{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v8XXhQ4sCrV0"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q nltk\n",
        "!pip install -q scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Z-cVurD0q8",
        "outputId": "ee33bb86-5d5b-40aa-965c-5431830d58c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'Reviews.csv'\n",
        "df = pd.read_csv(csv_path, on_bad_lines='skip', encoding='utf-8', engine='python')\n"
      ],
      "metadata": {
        "id": "zZFuDWHeD898"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = 'Text'\n",
        "reviews_series = df[text_col].dropna().reset_index(drop=True)\n",
        "reviews_series = reviews_series.iloc[:10000].copy()\n",
        "reviews_df = pd.DataFrame({'original': reviews_series})"
      ],
      "metadata": {
        "id": "JEVC4E-BGEWI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "4Ywq7G00GMJt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "vgaZlkoLGNR7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "reviews_df['cleaned'] = reviews_df['original'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv-hI2N9IsUE",
        "outputId": "c16abff6-c438-4294-f3ec-3cb066497ad4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:05<00:00, 1914.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(reviews_df['cleaned'])\n",
        "print( X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQtWwxRPIyGB",
        "outputId": "282559e7-9ec9-44d9-a36e-77c027922373"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_reviews(query, top_k=5):\n",
        "    q_clean = preprocess_text(query)\n",
        "    q_vec = vectorizer.transform([q_clean])\n",
        "    sims = cosine_similarity(q_vec, X).flatten()\n",
        "    top_idx = np.argsort(-sims)[:top_k]\n",
        "    results = []\n",
        "    for idx in top_idx:\n",
        "        results.append({\n",
        "            'score': float(sims[idx]),\n",
        "            'original': reviews_df.at[idx, 'original'],\n",
        "            'cleaned': reviews_df.at[idx, 'cleaned']\n",
        "        })\n",
        "    return results"
      ],
      "metadata": {
        "id": "Y_xIUE3oI2MH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in [\"great product with fast shipping\", \"disappointed\"]:\n",
        "    print('\\n===', q, '===')\n",
        "    for r in retrieve_reviews(q):\n",
        "        print(f\"\\nScore: {r['score']:.4f}\")\n",
        "        print('Original:', r['original'][:300])\n",
        "        print('Cleaned:', r['cleaned'][:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0TXtrirJHI8",
        "outputId": "bae1b716-a07e-44d1-e953-3f4dccc36e65"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== great product with fast shipping ===\n",
            "\n",
            "Score: 0.5160\n",
            "Original: Use frequently as we like to do Asian dishes at least once a week.  Love this product.  Fast shipping, as usual.  Would buy again.\n",
            "Cleaned: use frequently like asian dish least week love product fast shipping usual would buy\n",
            "\n",
            "Score: 0.3938\n",
            "Original: good products and fast shipping equals a happy me. a little pricey but you can hand pick a few good flavors...a few i cant find anywhere else so def worth the price\n",
            "Cleaned: good product fast shipping equal happy little pricey hand pick good flavor cant find anywhere else def worth price\n",
            "\n",
            "Score: 0.3927\n",
            "Original: My 3 cats can't get enough of these treats. A great product at a great price AND fast shipping. What more can 3 cats ask for?\n",
            "Cleaned: cat get enough treat great product great price fast shipping cat ask\n",
            "\n",
            "Score: 0.3662\n",
            "Original: Great Product, fast shipment,the food product tasted great. none of the fortune cookies where opened.  i would buy again from this seller!\n",
            "Cleaned: great product fast shipment food product tasted great none fortune cooky opened would buy seller\n",
            "\n",
            "Score: 0.3446\n",
            "Original: The cookies were kind of stail but other than that it was fast shipping and good packing the cookies weren't broken\n",
            "Cleaned: cooky kind stail fast shipping good packing cooky broken\n",
            "\n",
            "=== disappointed ===\n",
            "\n",
            "Score: 0.3495\n",
            "Original: We have not been disappointed with any flavor or these cookies.  They are the very best! Raspberry is my favorite:)\n",
            "Cleaned: disappointed flavor cooky best raspberry favorite\n",
            "\n",
            "Score: 0.3239\n",
            "Original: I received these a few weeks ago and was so excited I couldn't wait but when I opened them I was so disappointed there were only 3 flavors-mixed fruit, grape & strawberry. What's going on do they repackage them or what the box stated there would be other flavors but there weren't.Still I ate them bu\n",
            "Cleaned: received week ago excited wait opened disappointed flavor mixed fruit grape strawberry going repackage box stated would flavor still ate disappointed \n",
            "\n",
            "Score: 0.3081\n",
            "Original: I am a bit disappointed.  The flavor was not what I wanted or expected.\n",
            "Cleaned: bit disappointed flavor wanted expected\n",
            "\n",
            "Score: 0.2850\n",
            "Original: If you think there is no difference in balsamic, you must try this.  I promise you will not be disappointed.\n",
            "Cleaned: think difference balsamic must try promise disappointed\n",
            "\n",
            "Score: 0.2796\n",
            "Original: My whole family(7 people) tasted all 3 flavors and they are sickly sweet.  Very disappointed that product has sucralose.  I wouldn't buy it again\n",
            "Cleaned: whole family people tasted flavor sickly sweet disappointed product sucralose buy\n"
          ]
        }
      ]
    }
  ]
}